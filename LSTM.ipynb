{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "moderate-binding"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "moderate-binding",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flying-projector"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "id": "flying-projector",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "appreciated-bangkok"
      },
      "source": [
        "# Load the data"
      ],
      "id": "appreciated-bangkok"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "american-scientist"
      },
      "source": [
        "class HeartDeseaseDataset(Dataset): \n",
        "    \n",
        "    def __init__(self, path, any_disease=False):\n",
        "        \n",
        "        self.data = np.loadtxt(path, delimiter=\",\", dtype=np.float32, skiprows=1)\n",
        "        self.x = torch.from_numpy(self.data[:, 2:24])\n",
        "        if any_disease:\n",
        "            self.y = torch.from_numpy(np.amax(self.data[:, 24], axis=1))\n",
        "        else:\n",
        "            self.y = torch.from_numpy(self.data[:, 24])\n",
        "        \n",
        "\n",
        "        self.len = len(self.data)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]#, self.original[idx]"
      ],
      "id": "american-scientist",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arctic-religious"
      },
      "source": [
        "def create_dataloaders(dataset, batch_size, SEED):\n",
        "    lengths = [round(len(dataset) * split) for split in [TRAIN_SPLIT, VALIDATION_SPLIT, TEST_SPLIT]]\n",
        "    \n",
        "    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, lengths=lengths, generator=torch.Generator().manual_seed(SEED))\n",
        "    \n",
        "    train_dataloader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=4,\n",
        "        prefetch_factor=2,\n",
        "        persistent_workers=False,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    val_dataloader = torch.utils.data.DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=4,\n",
        "        prefetch_factor=2,\n",
        "        persistent_workers=False,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    test_dataloader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=1,\n",
        "        shuffle=True,\n",
        "        num_workers=4,\n",
        "        prefetch_factor=2,\n",
        "        persistent_workers=False,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    \n",
        "    print(f'Total dataset: {len(train_dataloader) + len(val_dataloader) + len(test_dataloader)}, '\n",
        "            f'train dataset: {len(train_dataloader)}, val dataset: {len(val_dataloader)}, test_dataset: {len(test_dataloader)}')\n",
        "    return train_dataloader, val_dataloader, test_dataloader\n"
      ],
      "id": "arctic-religious",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beneficial-convert",
        "outputId": "d0938f29-ea18-4288-ade0-15fe7a69805f"
      },
      "source": [
        "data_path = \"clean_data.csv\"\n",
        "SEED = 42\n",
        "\n",
        "TEST_SPLIT = 0.2\n",
        "VALIDATION_SPLIT = 0.21\n",
        "TRAIN_SPLIT = 1 - TEST_SPLIT - VALIDATION_SPLIT\n",
        "\n",
        "batch_size = 1\n",
        "\n",
        "dataset = HeartDeseaseDataset(data_path, any_disease=False)\n",
        "print(dataset.x.shape)\n",
        "train_dataloader, val_dataloader, test_dataloader = create_dataloaders(dataset, batch_size, SEED)\n",
        "\n",
        "print(len(test_dataloader))"
      ],
      "id": "beneficial-convert",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([11627, 22])\n",
            "Total dataset: 11627, train dataset: 6860, val dataset: 2442, test_dataset: 2325\n",
            "2325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "separated-bobby"
      },
      "source": [
        "# Define model and trainer"
      ],
      "id": "separated-bobby"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "valued-section"
      },
      "source": [
        "def accuracy_multi_prediction(pred, label):\n",
        "    res = 0\n",
        "    nb_prediction = pred.shape[1]\n",
        "\n",
        "    for i in range(nb_prediction):\n",
        "        if pred[0][i].item() == label[0][i].item():\n",
        "            res += 1\n",
        "    return res / nb_prediction"
      ],
      "id": "valued-section",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "excited-richardson"
      },
      "source": [
        "\n",
        "def accuracy(pred, label):\n",
        "    if round(pred[0].item()) == label[0].item():\n",
        "            return 1\n",
        "    return 0"
      ],
      "id": "excited-richardson",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cosmetic-dispatch"
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.num_classes = num_classes #number of classes\n",
        "        self.num_layers = num_layers #number of layers\n",
        "        self.input_size = input_size #input size\n",
        "        self.hidden_size = hidden_size #hidden state\n",
        "        self.seq_length = seq_length \n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
        "                          num_layers=num_layers, batch_first=True) #lstm\n",
        "        self.fc = nn.Linear(hidden_size, num_classes) \n",
        "\n",
        "    \n",
        "    def forward(self,x):\n",
        "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) #hidden state\n",
        "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) #internal state\n",
        "        # Propagate input through LSTM\n",
        "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
        "        out = self.fc(out) #Final Output\n",
        "        return out\n",
        " "
      ],
      "id": "cosmetic-dispatch",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fX6TQsEIGta"
      },
      "source": [
        "class Binary_AF:\n",
        "    def __init__(self, x):\n",
        "        self.x = x\n",
        "\n",
        "    def forward(self):\n",
        "        self.x[self.x <= 0] = 0\n",
        "        self.x[self.x > 0] = 1\n",
        "        return self.x\n",
        "\n",
        "    def backward(self):\n",
        "        return self.x"
      ],
      "id": "0fX6TQsEIGta",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsQyyljusOZ1"
      },
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob):\n",
        "        super(LSTMModel, self).__init__()\n",
        "\n",
        "        # Defining the number of layers and the nodes in each layer\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.layer_dim = layer_dim\n",
        "\n",
        "        # LSTM layers\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n",
        "        )\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.activation = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initializing hidden state for first input with zeros\n",
        "        h0 = torch.zeros(self.layer_dim, x.shape[0], self.hidden_dim).requires_grad_()\n",
        "\n",
        "        # Initializing cell state for first input with zeros\n",
        "        c0 = torch.zeros(self.layer_dim, x.shape[0], self.hidden_dim).requires_grad_()\n",
        "\n",
        "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
        "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
        "        # Forward propagation by passing in the input, hidden state, and cell state into the model\n",
        "        out, (hn, cn) = self.lstm(x.unsqueeze(0), (h0.detach(), c0.detach()))\n",
        "\n",
        "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
        "        # so that it can fit into the fully connected layer\n",
        "        out = out[:, -1, :]\n",
        "\n",
        "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
        "        out = self.fc(out)\n",
        "        out = self.activation(out)\n",
        "        \n",
        "        return out\n"
      ],
      "id": "FsQyyljusOZ1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "premium-distance"
      },
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.criterion = torch.nn.MSELoss(reduction=\"mean\")\n",
        "        self.optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.3)\n",
        "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode='max', factor=0.4, patience=2, cooldown=2)\n",
        "        self.max_val_acc = float('-inf')\n",
        "\n",
        "    def fit(self, epochs, train_dataloader, val_dataloader):\n",
        "        for curr_epoch in range(epochs):\n",
        "            self.model.train()\n",
        "            train_loss = val_loss = 0.0\n",
        "            pbar = tf.keras.utils.Progbar(target=len(train_dataloader))\n",
        "            print(f'Epoch {curr_epoch} / {epochs}')\n",
        "            for i, (data, labels) in enumerate(train_dataloader):\n",
        "\n",
        "                #forward\n",
        "                out = model(data)\n",
        "                loss = self.criterion(out, labels)\n",
        "                train_loss += loss\n",
        "                \n",
        "                #backward\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                \n",
        "                pbar.update(i + 1, values=\n",
        "                            [\n",
        "                                (\"loss\", train_loss.item()/(i + 1)),\n",
        "                                (\"lr\", self.scheduler.optimizer.param_groups[0]['lr'])\n",
        "                            ])\n",
        "\n",
        "                # gradient descent\n",
        "                self.optimizer.step()\n",
        "            \n",
        "            print('Validation')\n",
        "            \n",
        "            self.model.eval()\n",
        "            pbar = tf.keras.utils.Progbar(target=len(val_dataloader))\n",
        "            \n",
        "            val_acc = 0\n",
        "            with torch.no_grad():\n",
        "                for i, batch in enumerate(val_dataloader):\n",
        "                    acc = 0\n",
        "                    inputs, labels = batch\n",
        "                    outputs = self.model(inputs)\n",
        "                    val_loss += loss\n",
        "                    acc = accuracy(outputs, labels)\n",
        "                    pbar.update(i + 1, values=\n",
        "                            [\n",
        "                                (\"loss\", val_loss.item()/(i + 1)),\n",
        "                                (\"lr\", self.scheduler.optimizer.param_groups[0]['lr']),\n",
        "                                (\"acc\", acc)\n",
        "                            ])\n",
        "                    val_acc += acc\n",
        "\n",
        "            val_loss = val_loss / len(val_dataloader)\n",
        "            total_acc = val_acc / len(val_dataloader)\n",
        "            lr = self.scheduler.optimizer.param_groups[0]['lr']\n",
        "            self.scheduler.step(val_loss)\n",
        "            \n",
        "            if total_acc > self.max_val_acc:\n",
        "                print(f'Model saved. Loss updated: {self.max_val_acc:.3f} -> {total_acc:.3f}')\n",
        "                self.max_val_acc = total_acc\n",
        "                torch.save(self.model.state_dict(), f'lstm_{total_acc}.pt')\n",
        "                \n",
        "\n",
        "    def evaluate(self, test_dataloader, accuracy_function):\n",
        "        correct = total_loss = total = 0.0\n",
        "        #iterator = 0\n",
        "        \n",
        "        with torch.no_grad():       \n",
        "            # Iterate through test dataset\n",
        "            for i, (inputs, labels) in enumerate(test_dataloader):\n",
        "\n",
        "                pred = self.model(inputs)\n",
        "\n",
        "                loss = self.criterion(labels, pred)\n",
        "                total_loss += loss\n",
        "                    \n",
        "                # Total correct predictions\n",
        "                correct += accuracy_function(pred, labels)\n",
        "                #iterator += 1\n",
        "\n",
        "            total_accuracy = 100 * correct / len(test_dataloader)\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}. total loss: {}.'.format(len(test_dataloader), loss.item(), total_accuracy, total_loss))\n",
        "    "
      ],
      "id": "premium-distance",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wireless-insulation"
      },
      "source": [
        "# Train the model"
      ],
      "id": "wireless-insulation"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "second-alliance"
      },
      "source": [
        "num_classes = 1\n",
        "input_size = 22\n",
        "hidden_size = 2\n",
        "num_layers = 1\n",
        "seq_length = 22\n",
        "\n",
        "#model = LSTM(num_classes, input_size, hidden_size, num_layers, seq_length)\n",
        "\n",
        "input_dim = 22\n",
        "output_dim = 1\n",
        "hidden_dim = 64\n",
        "layer_dim = 3\n",
        "batch_size = 64\n",
        "dropout = 0.2\n",
        "learning_rate = 5e-3\n",
        "\n",
        "model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim, dropout)\n",
        "trainer = Trainer(model)"
      ],
      "id": "second-alliance",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmUjoxwX4sd6",
        "outputId": "f994b2c4-39f3-4d14-fc20-0e19f1a80d6b"
      },
      "source": [
        "trainer.fit(\n",
        "    5,\n",
        "    train_dataloader,\n",
        "    val_dataloader\n",
        ")"
      ],
      "id": "EmUjoxwX4sd6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 / 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  33/6860 [..............................] - ETA: 33s - loss: 0.2432 - lr: 0.0500"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6860/6860 [==============================] - 33s 5ms/step - loss: 0.2179 - lr: 0.0500\n",
            "Validation\n",
            "2442/2442 [==============================] - 6s 3ms/step - loss: 0.0985 - lr: 0.0500 - acc: 0.7158\n",
            "Model saved. Loss updated: -inf -> 0.716\n",
            "Epoch 1 / 5\n",
            "6860/6860 [==============================] - 33s 5ms/step - loss: 0.2178 - lr: 0.0500\n",
            "Validation\n",
            "2442/2442 [==============================] - 7s 3ms/step - loss: 0.0700 - lr: 0.0500 - acc: 0.7158\n",
            "Epoch 2 / 5\n",
            "6860/6860 [==============================] - 34s 5ms/step - loss: 0.2149 - lr: 0.0500\n",
            "Validation\n",
            "2442/2442 [==============================] - 7s 3ms/step - loss: 0.0877 - lr: 0.0500 - acc: 0.7158\n",
            "Epoch 3 / 5\n",
            "6860/6860 [==============================] - 34s 5ms/step - loss: 0.2175 - lr: 0.0500\n",
            "Validation\n",
            "2442/2442 [==============================] - 7s 3ms/step - loss: 0.0992 - lr: 0.0500 - acc: 0.7158\n",
            "Epoch 4 / 5\n",
            "6860/6860 [==============================] - 33s 5ms/step - loss: 0.2143 - lr: 0.0500\n",
            "Validation\n",
            "2442/2442 [==============================] - 6s 3ms/step - loss: 0.1561 - lr: 0.0500 - acc: 0.7158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "outer-christian",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb2774ac-f3bf-47e7-af5c-86b684abeade"
      },
      "source": [
        "trainer.evaluate(test_dataloader, accuracy)"
      ],
      "id": "outer-christian",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 2325. Loss: 0.10923855006694794. Accuracy: 71.18279569892474. total loss: 486.2972106933594.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "royal-status"
      },
      "source": [
        ""
      ],
      "id": "royal-status",
      "execution_count": null,
      "outputs": []
    }
  ]
}